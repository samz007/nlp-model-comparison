{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using review comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some of the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import bz2\n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the train and test data from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lines = bz2.BZ2File('input_data/amazon_data/train.ft.txt.bz2').readlines()\n",
    "test_file_lines = bz2.BZ2File('input_data/amazon_data/test.ft.txt.bz2').readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data into using utf-8 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
    "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains labels representing customers' feelings (either positive or negative) about the product. Thus, developing classifier models that can classify given comment as positive or negative can be the best approach for Sentiment Analysis. By observing the data, we can split the data into Sentences and Labels for test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_lables_and_sentences(file_lines):\n",
    "    labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in file_lines]\n",
    "    sentences = [x.split(' ', 1)[1][:-1].lower() for x in file_lines]\n",
    "    return labels, sentences\n",
    "    \n",
    "    \n",
    "train_lables, train_sentences = form_lables_and_sentences(train_file_lines)    \n",
    "test_lables, test_sentences = form_lables_and_sentences(test_file_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing is essential before developing a model. In Natural Language Processing, we need to clean the sentences to extract useful features from them. To clean the data in text format, we have to remove those symbols, characters, and spacing conventions that convey little or no information. Data cleaning for text comments can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_ALPHANUM = re.compile(r'[\\W]')\n",
    "NON_ASCII = re.compile(r'[^a-z0-1\\s]')\n",
    "\n",
    "def clean_sentences(sentences):\n",
    "    for i in range(len(sentences)):\n",
    "            if 'www.' in sentences[i] or 'http:' in sentences[i] or 'https:' in sentences[i] or '.com' in sentences[i]:\n",
    "                urls = re.findall(\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\", sentences[i])\n",
    "                for url in urls:\n",
    "                    sentences[i] = sentences[i].replace(url, \"<url>\")\n",
    "            sentences[i] = re.sub('\\d','0',sentences[i])\n",
    "            sentences[i] = re.sub('\\t','',sentences[i])\n",
    "            sentences[i] = re.sub('\\n','',sentences[i])\n",
    "            sentences[i] = NON_ALPHANUM.sub(r' ', sentences[i])\n",
    "            sentences[i] = NON_ASCII.sub(r'', sentences[i])\n",
    "            sentences[i] = sentences[i].strip()\n",
    "    return sentences\n",
    "        \n",
    "train_sentences = clean_sentences(train_sentences)\n",
    "test_sentences = clean_sentences(test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK is a python library that comes with numerous capabilities for humans to process the natural text. \n",
    "Getting some of the required packages for classifier design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/z003c93/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from nltk.classify import svm\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forming a dataframe for training and testing data that will have sentences and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stuning even for the non gamer  this sound tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the best soundtrack ever to anything   i m rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing   this soundtrack is my favorite music...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellent soundtrack  i truly like this soundt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remember  pull your jaw off the floor after he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Label\n",
       "0  stuning even for the non gamer  this sound tra...      1\n",
       "1  the best soundtrack ever to anything   i m rea...      1\n",
       "2  amazing   this soundtrack is my favorite music...      1\n",
       "3  excellent soundtrack  i truly like this soundt...      1\n",
       "4  remember  pull your jaw off the floor after he...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame({'Sentence': train_sentences, 'Label': train_lables})\n",
    "test_data = pd.DataFrame({'Sentence': test_sentences, 'Label': test_lables})\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecessary variables to clean some memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_file_lines, test_file_lines\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the step while cleaning text data in sentiment analysis can be removing stopwords from sentences as they don't really convey significant information in deciding the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me', 'more', 'ourselves', 'off', 'them', \"that'll\", 'hers', 'of', \"didn't\", 'needn', 'own', 'our', 'his', 'about', \"isn't\", 'wasn', 'few', \"hadn't\", 'hasn', 'he', 'isn', \"you'll\", 'but', 'both', 'an', 'not', 'at', 'who', 'when', 're', \"shan't\", 'ain', 'their', 'each', \"needn't\", 'too', \"mustn't\", 'through', 'having', 'yours', 'is', 'so', 'shouldn', 'itself', 'themselves', 'ma', 'haven', 'its', 'than', 'into', 'all', 'the', 'theirs', 'those', 'once', 'hadn', 'did', 'if', 'was', 'to', 'should', 'down', 's', 'mustn', 'then', 'just', 'this', 'doing', 'here', \"doesn't\", 'on', \"she's\", 'have', 'no', \"it's\", 'such', 'and', 'above', 'for', 'that', 'can', \"won't\", 'doesn', 't', 'ours', 'these', 'aren', 'yourselves', 'd', 've', \"shouldn't\", \"haven't\", 'very', 'she', 'there', 'in', \"wouldn't\", 'until', 'with', 'couldn', 'while', \"couldn't\", \"mightn't\", 'it', 'before', \"you're\", 'same', 'am', 'nor', \"you'd\", 'they', 'what', 'after', 'over', 'my', 'didn', 'y', 'will', 'because', 'which', 'don', 'himself', 'myself', 'from', 'her', 'why', 'mightn', 'shan', 'wouldn', 'i', 'are', 'yourself', 'were', 'below', \"wasn't\", 'how', 'had', 'other', 'does', 'as', 'now', 'only', 'some', 'where', 'again', 'or', 'a', 'most', 'herself', 'further', \"should've\", 'been', 'being', \"aren't\", 'won', 'your', \"hasn't\", 'by', 'under', \"you've\", \"don't\", \"weren't\", 'him', 'we', 'you', 'do', 'out', 'between', 'whom', 'during', 'be', 'weren', 'any', 'has', 'o', 'm', 'll', 'up', 'against'}\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the large dataset we can select 10k rows to train our model. Normally train to test ratio must be maintained near 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_train_featuresets = []\n",
    "all_fine_tuned_words = []\n",
    "\n",
    "def remove_stopwords(train_df):\n",
    "    for index, row in train_df.iterrows():\n",
    "        words_filtered = [e.lower() for e in row.Sentence.split() if len(e) >= 3]\n",
    "        words_without_stopwords = [word for word in words_filtered if not word in stopwords_set]\n",
    "        labeled_train_featuresets.append((words_without_stopwords, row.Label))\n",
    "        all_fine_tuned_words.extend(words_without_stopwords)\n",
    "        \n",
    "remove_stopwords(train_data.head(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the training set has nearly equal proportions of positive and negative sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x194ca8320>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "train_data.head(10000)['Label'].value_counts().plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start building features for our model. To get features from our document we can use Frequency Distribution function provided by ntlk. http://www.nltk.org/api/nltk.html?highlight=freqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    features = wordlist.keys()\n",
    "    return features\n",
    "\n",
    "words_features = get_word_features(all_fine_tuned_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a feature function that will be used by our classifier model while training the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_func(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in words_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NTLK library provides apply_features function that will help in generating our training set data based on the feature extraction function that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(features_func,labeled_train_featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier can be trained using NB_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the data we can check the most informative features used while training the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(waste) = True                0 : 1      =     42.6 : 1.0\n",
      "      contains(pathetic) = True                0 : 1      =     27.3 : 1.0\n",
      " contains(disappointing) = True                0 : 1      =     24.0 : 1.0\n",
      "         contains(awful) = True                0 : 1      =     21.9 : 1.0\n",
      "          contains(junk) = True                0 : 1      =     21.1 : 1.0\n",
      "       contains(medical) = True                1 : 0      =     19.8 : 1.0\n",
      "     contains(defective) = True                0 : 1      =     19.0 : 1.0\n",
      "         contains(worst) = True                0 : 1      =     18.8 : 1.0\n",
      "    contains(misleading) = True                0 : 1      =     18.3 : 1.0\n",
      "contains(disappointment) = True                0 : 1      =     18.0 : 1.0\n",
      "       contains(higgins) = True                0 : 1      =     16.4 : 1.0\n",
      "     contains(pointless) = True                0 : 1      =     16.4 : 1.0\n",
      "    contains(ridiculous) = True                0 : 1      =     16.4 : 1.0\n",
      "        contains(ripped) = True                0 : 1      =     15.7 : 1.0\n",
      "         contains(trite) = True                0 : 1      =     15.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NB_classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit other classifiers on our training dataset we can use wrapper classifier- SklearnClassifier provided by NLTK library. This classifier helps in mapping sklearn classifier to natural language processing classifiers. Selecting a few classifiers that might perform better than Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from scipy.stats import chi2\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#get models from sklearn\n",
    "models_from_sklearn = [('SVM',LinearSVC()),\n",
    "                       ('LR', LogisticRegression(solver='lbfgs')),  \n",
    "                       ('DT',DecisionTreeClassifier(criterion='entropy')), \n",
    "                       ('RF',RandomForestClassifier(n_estimators=100, criterion='entropy'))]\n",
    "classifiers_for_comparison = []\n",
    "\n",
    "for name,model in models_from_sklearn:\n",
    "    text_classifier = SklearnClassifier(model).train(training_set)\n",
    "    classifiers_for_comparison.append( (name , text_classifier) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the test data into five subsets that can be tested independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset_one = test_data[:1000]\n",
    "test_subset_two = test_data[2000:3000]\n",
    "test_subset_three = test_data[4000:5000]\n",
    "test_subset_four = test_data[6000:7000]\n",
    "test_subset_five = test_data[9000:10000]\n",
    "test_sets_group = [test_subset_one,test_subset_two, test_subset_three,test_subset_four ,test_subset_five]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our test sets ready, we can use our models for predictions on test sets. F1-score and Accuracy of these models can be compared to select best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "models = []\n",
    "models.append(('NB', NB_classifier))\n",
    "for name, classifier in classifiers_for_comparison:\n",
    "    models.append((name,classifier))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "Average F1 score for NB is 0.844 with standard deviation as 0.012 \n",
      "Average Accuracy for NB is 0.840 with standard deviation as 0.017  \n",
      "\n",
      "============================================\n",
      "Average F1 score for SVM is 0.825 with standard deviation as 0.018 \n",
      "Average Accuracy for SVM is 0.820 with standard deviation as 0.023  \n",
      "\n",
      "============================================\n",
      "Average F1 score for LR is 0.847 with standard deviation as 0.016 \n",
      "Average Accuracy for LR is 0.843 with standard deviation as 0.019  \n",
      "\n",
      "============================================\n",
      "Average F1 score for DT is 0.735 with standard deviation as 0.011 \n",
      "Average Accuracy for DT is 0.729 with standard deviation as 0.015  \n",
      "\n",
      "============================================\n",
      "Average F1 score for RF is 0.840 with standard deviation as 0.013 \n",
      "Average Accuracy for RF is 0.834 with standard deviation as 0.018  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "    for test_data in test_sets_group:\n",
    "        ground_truth = test_data['Label']\n",
    "        predictions = []\n",
    "        for obj in test_data['Sentence']: \n",
    "            res =  model.classify(features_func(obj.split()))\n",
    "            predictions.append(res)\n",
    "        accuracy = accuracy_score(ground_truth, predictions)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_score_value = f1_score(ground_truth, predictions)\n",
    "        f1_scores.append(f1_score_value)\n",
    "    print(\"============================================\")\n",
    "    print(\"Average F1 score for %s is %0.3f with standard deviation as %0.3f \" %(name, np.mean(f1_scores),np.std(f1_scores)))\n",
    "    print(\"Average Accuracy for %s is %0.3f with standard deviation as %0.3f  \\n\" %(name, np.mean(accuracy_scores),np.std(accuracy_scores)))\n",
    "    results.append(accuracy_scores)\n",
    "    names.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the accuracy obtained for different models using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion we can say that, Logistic Regression and Naive Bayes classifier give better results than other models with acceptable standard deviation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
